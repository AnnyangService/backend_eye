"""
RAGìš© ì„ë² ë”© ìƒì„± ëª¨ë“ˆ
km-bertë¥¼ ì‚¬ìš©í•˜ì—¬ ì²­í‚¹ëœ ë¬¸ì„œì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ë³„ë„ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import torch
import numpy as np
import json
import os
import logging
from typing import List, Dict, Any
from transformers import AutoModel, AutoTokenizer

logger = logging.getLogger(__name__)

class RAGEmbeddingGenerator:
    """
    RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì„ë² ë”© ìƒì„±ê¸°
    km-bertë¥¼ ì‚¬ìš©í•˜ì—¬ ì²­í‚¹ëœ ë¬¸ì„œì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ë³„ë„ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, model_name: str = "madatnlp/km-bert", tokenizer_name: str = "snunlp/KR-BERT-char16424"):
        """
        RAGEmbeddingGenerator ì´ˆê¸°í™”
        
        Args:
            model_name (str): ì‚¬ìš©í•  ëª¨ë¸ëª… (ê¸°ë³¸ê°’: km-bert)
            tokenizer_name (str): ì‚¬ìš©í•  í† í¬ë‚˜ì´ì €ëª…
        """
        self.model_name = model_name
        self.tokenizer_name = tokenizer_name
        self.model = None
        self.tokenizer = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # embeddings ë””ë ‰í† ë¦¬ ìƒì„±
        self.embeddings_dir = "C:/Users/jjj53/Desktop/Hi_MeoW/backend_eye/app/rag/embeddings"
        os.makedirs(self.embeddings_dir, exist_ok=True)
        
        # ëª¨ë¸ ë¡œë“œ
        self._load_model()
    
    def _load_model(self):
        """ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            logger.info(f"ëª¨ë¸ ë¡œë“œ ì‹œì‘: {self.model_name}")
            logger.info(f"í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹œì‘: {self.tokenizer_name}")
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_name)
            logger.info(f"í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ: {type(self.tokenizer).__name__}")
            
            # ëª¨ë¸ ë¡œë“œ
            self.model = AutoModel.from_pretrained(self.model_name)
            self.model = self.model.to(self.device)
            self.model.eval()
            
            logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ, ë””ë°”ì´ìŠ¤: {self.device}")
            
            # ëª¨ë¸ ì •ë³´ ì¶œë ¥
            total_params = sum(p.numel() for p in self.model.parameters())
            logger.info(f"ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"RAGEmbeddingGenerator ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def generate_embeddings_batch(self, texts: List[str], max_length: int = 512) -> np.ndarray:
        """
        ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ë°°ì¹˜ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            texts (List[str]): ì„ë² ë”©ì„ ìƒì„±í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            max_length (int): ìµœëŒ€ í† í° ê¸¸ì´
            
        Returns:
            np.ndarray: ì„ë² ë”© ë²¡í„°ë“¤ (N x 768)
        """
        try:
            if self.model is None or self.tokenizer is None:
                raise Exception("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            if not texts:
                return np.array([])
            
            # í† í¬ë‚˜ì´ì§• (ë°°ì¹˜ ì²˜ë¦¬)
            inputs = self.tokenizer(
                texts,
                return_tensors="pt",
                max_length=max_length,
                padding=True,
                truncation=True
            )
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ì¶”ë¡  ì‹¤í–‰
            with torch.no_grad():
                outputs = self.model(**inputs)
                
                # [CLS] í† í°ì˜ ì„ë² ë”©ì„ ì‚¬ìš©
                cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()
                
                return cls_embeddings
                
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def save_embeddings(self, chunk_ids: List[str], embeddings: np.ndarray) -> Dict[str, str]:
        """
        ì„ë² ë”©ë“¤ì„ ê°œë³„ .npy íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            chunk_ids (List[str]): ì²­í‚¹ ID ë¦¬ìŠ¤íŠ¸
            embeddings (np.ndarray): ì„ë² ë”© ë°°ì—´ (N x 768)
            
        Returns:
            Dict[str, str]: ì²­í‚¹ IDì™€ ì„ë² ë”© íŒŒì¼ ê²½ë¡œì˜ ë§¤í•‘
        """
        try:
            embedding_paths = {}
            
            for i, chunk_id in enumerate(chunk_ids):
                # íŒŒì¼ëª… ìƒì„± (íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬)
                safe_filename = chunk_id.replace('/', '_').replace('\\', '_').replace(':', '_')
                embedding_file = os.path.join(self.embeddings_dir, f"{safe_filename}.npy")
                
                # ì„ë² ë”© ì €ì¥
                np.save(embedding_file, embeddings[i])
                embedding_paths[chunk_id] = embedding_file
                
                logger.debug(f"ì„ë² ë”© ì €ì¥: {chunk_id} -> {embedding_file}")
            
            logger.info(f"ì´ {len(chunk_ids)}ê°œì˜ ì„ë² ë”©ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            return embedding_paths
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def generate_and_save_embeddings(self, chunks: List[Dict[str, Any]], max_length: int = 512) -> Dict[str, str]:
        """
        ì²­í‚¹ëœ ë¬¸ì„œë“¤ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            chunks (List[Dict[str, Any]]): ì²­í‚¹ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            max_length (int): ìµœëŒ€ í† í° ê¸¸ì´
            
        Returns:
            Dict[str, str]: ì²­í‚¹ IDì™€ ì„ë² ë”© íŒŒì¼ ê²½ë¡œì˜ ë§¤í•‘
        """
        try:
            if not chunks:
                return {}
            
            # content í…ìŠ¤íŠ¸ë“¤ê³¼ ID ì¶”ì¶œ
            contents = [chunk['content'] for chunk in chunks]
            chunk_ids = [chunk['id'] for chunk in chunks]
            
            # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„±
            embeddings = self.generate_embeddings_batch(contents, max_length)
            
            # ì„ë² ë”© ì €ì¥
            embedding_paths = self.save_embeddings(chunk_ids, embeddings)
            
            logger.info(f"ì´ {len(chunks)}ê°œì˜ ì²­í‚¹ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            return embedding_paths
            
        except Exception as e:
            logger.error(f"ì²­í‚¹ ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì²­í‚¹ ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def process_chunks_file(self, chunks_file: str, save_mapping: bool = True):
        """
        ì €ì¥ëœ ì²­í‚¹ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            chunks_file (str): ì²­í‚¹ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            save_mapping (bool): ì²­í‚¹ IDì™€ ì„ë² ë”© íŒŒì¼ ê²½ë¡œ ë§¤í•‘ì„ ì €ì¥í• ì§€ ì—¬ë¶€
        """
        try:
            # ì²­í‚¹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
            with open(chunks_file, 'r', encoding='utf-8') as f:
                chunks = json.load(f)
            
            logger.info(f"ì²­í‚¹ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {chunks_file}")
            print(f"ğŸ“„ ì²­í‚¹ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {len(chunks)}ê°œ")
            
            # ì„ë² ë”© ìƒì„± ë° ì €ì¥
            embedding_paths = self.generate_and_save_embeddings(chunks)
            
            print(f"âœ… ì´ {len(embedding_paths)}ê°œì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸ“ ì„ë² ë”© ì €ì¥ ê²½ë¡œ: {self.embeddings_dir}/")
            
            return embedding_paths
            
        except Exception as e:
            logger.error(f"ì²­í‚¹ ë°ì´í„° ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì²­í‚¹ ë°ì´í„° ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def load_embedding(self, chunk_id: str) -> np.ndarray:
        """
        íŠ¹ì • ì²­í‚¹ì˜ ì„ë² ë”©ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            chunk_id (str): ì²­í‚¹ ID
            
        Returns:
            np.ndarray: ì„ë² ë”© ë²¡í„°
        """
        try:
            # íŒŒì¼ëª… ìƒì„±
            safe_filename = chunk_id.replace('/', '_').replace('\\', '_').replace(':', '_')
            embedding_file = os.path.join(self.embeddings_dir, f"{safe_filename}.npy")
            
            if not os.path.exists(embedding_file):
                raise FileNotFoundError(f"ì„ë² ë”© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {embedding_file}")
            
            # ì„ë² ë”© ë¡œë“œ
            embedding = np.load(embedding_file)
            return embedding
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


if __name__ == "__main__":
    # ì²­í‚¹ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    chunks_file = "C:/Users/jjj53/Desktop/Hi_MeoW/backend_eye/app/rag/chunks/chunks.json"
    
    if os.path.exists(chunks_file):
        # ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”
        embedding_generator = RAGEmbeddingGenerator()
        
        # ì„ë² ë”© ìƒì„± ë° ì €ì¥
        embedding_paths = embedding_generator.process_chunks_file(chunks_file)
        
        print(f"âœ… ì´ {len(embedding_paths)}ê°œì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        
    else:
        print(f"âŒ ì²­í‚¹ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {chunks_file}")
        print("ë¨¼ì € chunk_storage.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì²­í‚¹ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")